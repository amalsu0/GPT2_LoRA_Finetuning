{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daa923fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: evaluate in /home/student/.local/lib/python3.10/site-packages (0.4.3)\n",
      "Requirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2.2.1)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: fsspec[http]>=2021.05.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2024.2.0)\n",
      "Requirement already satisfied: packaging in /home/student/.local/lib/python3.10/site-packages (from evaluate) (24.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (4.66.2)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/student/.local/lib/python3.10/site-packages (from evaluate) (0.21.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/student/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.1)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.3)\n",
      "Requirement already satisfied: filelock in /home/student/.local/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/student/.local/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.10.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/student/.local/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/student/.local/lib/python3.10/site-packages (from pandas->evaluate) (2024.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/student/.local/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.5)\n",
      "Requirement already satisfied: six>=1.5 in /home/student/.local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36151a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/student/.local/lib/python3.10/site-packages (1.6.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/student/.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f9fbdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from peft import LoraConfig, TaskType\n",
    "from peft import get_peft_model\n",
    "from peft import AutoPeftModelForSequenceClassification \n",
    "\n",
    "from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "\n",
    "from workspace_utils import active_session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f28c4a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'input', 'labels'],\n",
       "        num_rows: 6507\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'input', 'labels'],\n",
       "        num_rows: 2169\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset\n",
    "ds = load_dataset(\"medalpaca/medical_meadow_health_advice\", split='train')\n",
    "ds = ds.remove_columns(\"instruction\")\n",
    "\n",
    "mapping = {\"This is no advice\":0, \"This is a weak advice\":1, \"This is a strong advice\":2}\n",
    "ds = ds.add_column(\"labels\", [mapping[i] for i in ds[\"output\"]])\n",
    "\n",
    "ds = ds.train_test_split(test_size=0.25)\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "904115e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [0,1,2]\n",
    "label_count = len(labels)\n",
    "\n",
    "id2label = {0:\"No advice\", 1:\"Weak advice\", 2:\"Strong advice\"}\n",
    "label2id = {\"No advice\":0, \"Weak advice\":1, \"Strong advice\":2}\n",
    "\n",
    "label_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4935cb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7185a1924fa14f5dabd379f840af8f04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6507 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a24d848b544b4fa67254fc6bca2461",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2169 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "if not tokenizer.pad_token:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    tokenized_dataset = {}\n",
    "tokenized_dataset[\"train\"] = ds[\"train\"].map(lambda x: tokenizer(x[\"input\"], padding=\"max_length\", truncation=True), batched=True)\n",
    "tokenized_dataset[\"test\"] = ds[\"test\"].map(lambda x: tokenizer(x[\"input\"], padding=\"max_length\", truncation=True), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f551c63a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=768, out_features=3, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Foundation Model without changing out_features in the last Linear layer\n",
    "foundation = AutoModelForSequenceClassification.from_pretrained(\"gpt2\")\n",
    "foundation.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# Foundation model with changing out_features to 3 in the last Linear layer\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"gpt2\", num_labels=label_count, id2label=id2label, label2id=label2id)\n",
    "model.config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "# to cuda\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "foundation.to(device)\n",
    "model.to(device)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd5fce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: is this a 0:No advice, 1:Weak advice, 2:Strong advice? As detailed in Table 2 and Figure 2, this biker position was shown here to reduce myocardial attenuation and corresponding artifacts, as compared with the sitting or supine position, with this reduction mainly involving the basal portion of the inferior area, similarly to that previously reported for the prone versus the supine position. \n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame(ds[\"test\"])\n",
    "\n",
    "# formulate as questions to ask the foundation model and give instuctions\n",
    "test_df[\"input_question\"] = test_df[\"input\"].apply(lambda x :f\"Question: is this a 0:No advice, 1:Weak advice, 2:Strong advice? {x}\")\n",
    "print(test_df[\"input_question\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d917d419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, text):\n",
    "    input_tokens =  tokenizer(text,  return_tensors=\"pt\", padding=\"max_length\", truncation=True).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**input_tokens)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "    probs = torch.nn.functional.softmax(logits, dim=1)\n",
    "    return probs.argmax().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db3c1fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from foundation model\n",
    "test_df[\"foundation_predictions\"] = test_df[\"input_question\"].map(lambda x: predict(foundation,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0611ba24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7514983863531581}\n"
     ]
    }
   ],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "foundation_results = accuracy_metric.compute(references=test_df[\"labels\"], predictions=test_df[\"foundation_predictions\"])\n",
    "print(foundation_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 152,064 || all params: 124,591,872 || trainable%: 0.12204969518396834\n"
     ]
    }
   ],
   "source": [
    "# convert to PEFT model\n",
    "config = LoraConfig(task_type=TaskType.SEQ_CLS,inference_mode=False,r=4,lora_alpha=16,lora_dropout=0.1,fan_in_fan_out=True,)\n",
    "lora_model = get_peft_model(model, config)\n",
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b330acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78f8720e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1627' max='1627' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1627/1627 26:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.584300</td>\n",
       "      <td>0.576628</td>\n",
       "      <td>0.756109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='543' max='543' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [543/543 03:22]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5766279697418213,\n",
       " 'eval_accuracy': 0.756108805901337,\n",
       " 'eval_runtime': 203.3324,\n",
       " 'eval_samples_per_second': 10.667,\n",
       " 'eval_steps_per_second': 2.671,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tuning using PEFT\n",
    "training_args = TrainingArguments(\n",
    "        output_dir=\"./results\",\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "    #     load_best_model_at_end=True,\n",
    "        num_train_epochs=1,\n",
    "    #     weight_decay=0.01,    \n",
    "    #     remove_unused_columns=False \n",
    "\n",
    "    )\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "        model=lora_model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_dataset['train'],#train_lora,\n",
    "        eval_dataset=tokenized_dataset['test'],#test_lora,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "\n",
    "# with active_session():\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# save fine-tuned PEFT\n",
    "lora_model.save_pretrained(\"gpt2-lora\")\n",
    "\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e58e7154",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): GPT2ForSequenceClassification(\n",
       "      (transformer): GPT2Model(\n",
       "        (wte): Embedding(50257, 768)\n",
       "        (wpe): Embedding(1024, 768)\n",
       "        (drop): Dropout(p=0.1, inplace=False)\n",
       "        (h): ModuleList(\n",
       "          (0-11): 12 x GPT2Block(\n",
       "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): GPT2Attention(\n",
       "              (c_attn): Linear(\n",
       "                in_features=768, out_features=2304, bias=True\n",
       "                (lora_dropout): ModuleDict(\n",
       "                  (default): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (lora_A): ModuleDict(\n",
       "                  (default): Linear(in_features=768, out_features=4, bias=False)\n",
       "                )\n",
       "                (lora_B): ModuleDict(\n",
       "                  (default): Linear(in_features=4, out_features=2304, bias=False)\n",
       "                )\n",
       "                (lora_embedding_A): ParameterDict()\n",
       "                (lora_embedding_B): ParameterDict()\n",
       "              )\n",
       "              (c_proj): Conv1D()\n",
       "              (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "              (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): GPT2MLP(\n",
       "              (c_fc): Conv1D()\n",
       "              (c_proj): Conv1D()\n",
       "              (act): NewGELUActivation()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (score): ModulesToSaveWrapper(\n",
       "        (original_module): Linear(in_features=768, out_features=3, bias=False)\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): Linear(in_features=768, out_features=3, bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_lora_model = AutoPeftModelForSequenceClassification.from_pretrained(\"gpt2-lora\", num_labels=label_count)\n",
    "ft_lora_model.config.pad_token_id = ft_lora_model.config.eos_token_id\n",
    "ft_lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302785e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inference\n",
    "x = \"not recommended\"\n",
    "predict(ft_lora_model,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b12402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions from the finetuned model\n",
    "test_df[\"finetuned_predictions\"] = test_df[\"input\"].map(lambda x: predict(ft_lora_model,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c3fc640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output</th>\n",
       "      <th>input</th>\n",
       "      <th>labels</th>\n",
       "      <th>input_question</th>\n",
       "      <th>foundation_predictions</th>\n",
       "      <th>finetuned_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2164</th>\n",
       "      <td>This is a strong advice</td>\n",
       "      <td>Thus, EPA and DHA supplementation should be co...</td>\n",
       "      <td>2</td>\n",
       "      <td>Question: is this a 0:No advice, 1:Weak advice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>This is no advice</td>\n",
       "      <td>Meta-analysis showed no significant associatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: is this a 0:No advice, 1:Weak advice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>This is a weak advice</td>\n",
       "      <td>MPV could be a promising and easily available ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Question: is this a 0:No advice, 1:Weak advice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2167</th>\n",
       "      <td>This is no advice</td>\n",
       "      <td>Its therapeutic effect is independent of its e...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: is this a 0:No advice, 1:Weak advice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>This is no advice</td>\n",
       "      <td>Nitrous oxide inhalation was preferable to inj...</td>\n",
       "      <td>0</td>\n",
       "      <td>Question: is this a 0:No advice, 1:Weak advice...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       output  \\\n",
       "2164  This is a strong advice   \n",
       "2165        This is no advice   \n",
       "2166    This is a weak advice   \n",
       "2167        This is no advice   \n",
       "2168        This is no advice   \n",
       "\n",
       "                                                  input  labels  \\\n",
       "2164  Thus, EPA and DHA supplementation should be co...       2   \n",
       "2165  Meta-analysis showed no significant associatio...       0   \n",
       "2166  MPV could be a promising and easily available ...       1   \n",
       "2167  Its therapeutic effect is independent of its e...       0   \n",
       "2168  Nitrous oxide inhalation was preferable to inj...       0   \n",
       "\n",
       "                                         input_question  \\\n",
       "2164  Question: is this a 0:No advice, 1:Weak advice...   \n",
       "2165  Question: is this a 0:No advice, 1:Weak advice...   \n",
       "2166  Question: is this a 0:No advice, 1:Weak advice...   \n",
       "2167  Question: is this a 0:No advice, 1:Weak advice...   \n",
       "2168  Question: is this a 0:No advice, 1:Weak advice...   \n",
       "\n",
       "      foundation_predictions  finetuned_predictions  \n",
       "2164                       0                      0  \n",
       "2165                       0                      0  \n",
       "2166                       0                      0  \n",
       "2167                       0                      0  \n",
       "2168                       0                      0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# index 2164 has different predictions from foundation model and finetuned model\n",
    "test_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46d72dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.7574919317657907}\n"
     ]
    }
   ],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "finetuning_results = accuracy_metric.compute(references=test_df[\"labels\"], predictions=test_df[\"finetuned_predictions\"])\n",
    "print(finetuning_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6eef9a",
   "metadata": {},
   "source": [
    "# There is a little increase in the accuarcy after finetuning.\n",
    "#  I only did 1 epoch, because on resources limitations and connection problems in the workspace."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
